"""
Streamlit dashboard for exploring board game predictions.

This dashboard loads predictions from BigQuery and provides interactive visualizations
for exploring predicted geek ratings, complexity, ratings, and other metrics across
different publication years and prediction jobs.
"""

import sys
import os
import streamlit as st
import polars as pl
import plotly.express as px
from datetime import datetime, timedelta
import pandas as pd

# Add project root to Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.insert(0, project_root)
from src.data.bigquery_uploader import BigQueryUploader  # noqa: E402


def check_bigquery_connection(environment: str = "dev") -> bool:
    """
    Check if BigQuery connection is available.

    Args:
        environment: BigQuery environment to use (dev/prod)

    Returns:
        bool: True if connection successful, False otherwise
    """
    try:
        uploader = BigQueryUploader(environment=environment)
        # Try to execute a simple query
        uploader.get_prediction_summary()
        return True
    except Exception as e:
        st.error(f"Error connecting to BigQuery: {e}")
        return False


def get_available_jobs(environment: str = "dev", days_back: int = 30) -> pd.DataFrame:
    """
    Get list of available prediction jobs.

    Args:
        environment: BigQuery environment to use (dev/prod)
        days_back: Number of days to look back for jobs

    Returns:
        DataFrame with job information
    """
    try:
        uploader = BigQueryUploader(environment=environment)
        jobs = uploader.get_prediction_summary()

        # Filter to recent jobs
        if len(jobs) > 0:
            jobs["latest_prediction"] = pd.to_datetime(jobs["latest_prediction"])
            cutoff_date = datetime.now() - timedelta(days=days_back)
            jobs = jobs[jobs["latest_prediction"] >= cutoff_date]

        return jobs
    except Exception as e:
        st.error(f"Error getting available jobs: {e}")
        return pd.DataFrame()


def load_predictions_from_bigquery(
    environment: str = "dev",
    job_id: str = None,
    start_date: str = None,
    end_date: str = None,
) -> pl.DataFrame:
    """
    Load predictions from BigQuery.

    Args:
        environment: BigQuery environment to use (dev/prod)
        job_id: Optional job ID to filter by
        start_date: Optional start date (YYYY-MM-DD)
        end_date: Optional end date (YYYY-MM-DD)

    Returns:
        Polars DataFrame with predictions
    """
    try:
        uploader = BigQueryUploader(environment=environment)
        df = uploader.query_predictions(
            job_id=job_id, start_date=start_date, end_date=end_date
        )

        # Convert to polars for consistency with existing code
        return pl.from_pandas(df)
    except Exception as e:
        st.error(f"Error loading predictions from BigQuery: {e}")
        return None


def show_help():
    """Show help information in the sidebar."""
    with st.sidebar.expander("â„¹ï¸ Help & Documentation"):
        st.markdown(
            """
        ### Using the Dashboard
        
        This dashboard displays predictions for board game ratings and characteristics
        loaded from BigQuery. The predictions are generated by the scoring service
        and include:
        
        - Geek Rating (Bayesian average)
        - Complexity Score
        - Average Rating
        - Number of Users Rating
        - Rating Probability
        
        ### Filtering Data
        
        1. **Environment**: Choose between dev/prod data
        2. **Date Range**: Filter predictions by date
        3. **Job Selection**: Choose specific prediction runs
        4. **Year Filter**: Filter by publication year
        
        ### Troubleshooting
        
        If you encounter issues:
        
        1. Check BigQuery connection:
           - Verify credentials are set up
           - Ensure you have access to the dataset
        
        2. No predictions showing:
           - Verify scoring service has run recently
           - Check date range filter
           - Try switching to 'dev' environment
        
        3. Missing data:
           - Ensure all required models were used
           - Check for failed prediction jobs
        
        ### Need Help?
        
        For technical issues or questions, please check:
        - Project documentation
        - BigQuery logs
        - Scoring service status
        """
        )


def main():
    st.set_page_config(page_title="Predictions Explorer", layout="wide")

    st.title("Predictions Explorer")

    # Show documentation
    show_help()

    # Sidebar configuration
    st.sidebar.header("Settings")

    # Environment selection
    environment = st.sidebar.selectbox(
        "Environment",
        options=["dev", "prod"],
        index=0,  # Default to dev
        help="Select the environment to load predictions from",
    )

    # Check BigQuery connection
    if not check_bigquery_connection(environment):
        st.error(
            """
            ### ðŸš« BigQuery Connection Failed
            
            Could not connect to BigQuery. This could be due to:
            
            1. Missing or invalid credentials
            2. Network connectivity issues
            3. Insufficient permissions
            
            **Troubleshooting Steps:**
            1. Check if credentials are properly configured
            2. Verify network connectivity
            3. Ensure you have access to the BigQuery dataset
            4. Try switching to 'dev' environment
            
            See the Help section in the sidebar for more information.
            """
        )
        return

    # Load available jobs
    with st.spinner("Loading available prediction jobs..."):
        jobs = get_available_jobs(environment)
        if len(jobs) == 0:
            st.error(
                """
                ### ðŸ“­ No Prediction Jobs Found
                
                No prediction jobs were found in BigQuery. This could mean:
                
                1. No predictions have been generated yet
                2. The scoring service hasn't run recently
                3. You're looking in the wrong environment
                
                **Suggestions:**
                - Check if the scoring service is running
                - Try switching environments (dev/prod)
                - Verify the scoring service configuration
                
                See the Help section for more details about prediction jobs.
                """
            )
            return

    # Date range filter
    st.sidebar.subheader("Date Filter")

    # Get min/max dates from jobs
    min_date = jobs["latest_prediction"].min().date()
    max_date = jobs["latest_prediction"].max().date()

    col1, col2 = st.sidebar.columns(2)
    with col1:
        start_date = st.date_input(
            "Start Date",
            value=min_date,
            min_value=min_date,
            max_value=max_date,
            help="Filter predictions from this date",
        )
    with col2:
        end_date = st.date_input(
            "End Date",
            value=max_date,
            min_value=min_date,
            max_value=max_date,
            help="Filter predictions up to this date",
        )

    # Filter jobs by date range
    date_filtered_jobs = jobs[
        (jobs["latest_prediction"].dt.date >= start_date)
        & (jobs["latest_prediction"].dt.date <= end_date)
    ]

    if len(date_filtered_jobs) == 0:
        st.error("No prediction jobs found in the selected date range.")
        return

    # Job selection
    st.sidebar.subheader("Select Prediction Job")

    # Format job options for display
    job_options = []
    for _, job in date_filtered_jobs.iterrows():
        latest_pred = pd.to_datetime(job["latest_prediction"]).strftime(
            "%Y-%m-%d %H:%M"
        )
        option_text = f"{latest_pred} ({job['num_predictions']} predictions)"
        job_options.append((job["job_id"], option_text))

    selected_job_id = st.sidebar.selectbox(
        "Available Jobs",
        options=[j[0] for j in job_options],
        format_func=lambda x: next(j[1] for j in job_options if j[0] == x),
        help="Select a prediction job to explore",
    )

    # Show job details
    selected_job = jobs[jobs["job_id"] == selected_job_id].iloc[0]
    st.sidebar.markdown("**Job Details:**")
    st.sidebar.markdown(
        f"""
    - Hurdle Model: `{selected_job['hurdle_experiment']}`
    - Complexity Model: `{selected_job['complexity_experiment']}`
    - Rating Model: `{selected_job['rating_experiment']}`
    - Users Rated Model: `{selected_job['users_rated_experiment']}`
    """
    )

    try:
        # Load predictions for selected job
        with st.spinner("Loading predictions from BigQuery..."):
            predictions = load_predictions_from_bigquery(
                environment=environment,
                job_id=selected_job_id,
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d"),
            )

        if predictions is None:
            st.error(
                """
                Could not load predictions. This could be due to:
                - BigQuery connection issues
                - Missing or invalid data
                - Insufficient permissions
                
                Please check your configuration and try again.
                """
            )
            return

        if len(predictions) == 0:
            st.warning("No predictions found for the selected criteria.")
            return

    except Exception as e:
        st.error(f"Error loading predictions: {str(e)}")
        st.error("Please check your configuration and try again.")
        return

    # Convert to pandas for easier manipulation
    df = predictions.to_pandas()

    # Debug: Print available columns
    st.sidebar.subheader("Available Columns")
    st.sidebar.write(df.columns.tolist())

    # Tabs for different views
    tab1, tab2, tab3 = st.tabs(
        ["Predictions Table", "Geek Rating Distribution", "Analysis"]
    )

    with tab1:
        # Prepare year buckets
        df["year_bucket"] = df["year_published"].apply(
            lambda x: "Other" if x < 2010 else str(x)
        )

        # rename columns if they exist
        if "predicted_geek_rating" not in df.columns:
            if "geek_rating" in df.columns:
                df["predicted_geek_rating"] = df["geek_rating"]
            else:
                st.error("Could not find predicted geek rating column")
                return

        if "actual_geek_rating" not in df.columns and "actual" in df.columns:
            df["actual_geek_rating"] = df["actual"]

        # Year selection
        unique_years = sorted(
            df["year_bucket"].unique(), key=lambda x: (x == "Other", x)
        )

        # Find the year closest to the current year, excluding "Other"
        current_year = datetime.now().year
        numeric_years = [int(year) for year in unique_years if year != "Other"]
        closest_year = min(numeric_years, key=lambda x: abs(x - current_year))

        default_year_index = unique_years.index(str(closest_year))
        selected_year = st.selectbox(
            "Select Publication Year", unique_years, index=default_year_index
        )

        # Filter dataframe
        filtered_df = df[df["year_bucket"] == selected_year]

        # Sort by geek_rating in descending order
        filtered_df = filtered_df.sort_values("predicted_geek_rating", ascending=False)

        # Basic statistics
        st.header("Prediction Statistics")
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("Total Games", len(filtered_df))

        with col2:
            st.metric(
                "Average Geek Rating",
                f"{filtered_df['predicted_geek_rating'].mean():.2f}",
            )

        with col3:
            st.metric(
                "Median Geek Rating",
                f"{filtered_df['predicted_geek_rating'].median():.2f}",
            )

        # st.header("Predictions Table")

        # Columns to display
        display_columns = [
            "year_published",
            "game_id",
            "name",
            "actual_geek_rating",
            "predicted_geek_rating",
            "predicted_hurdle_prob",
            "predicted_complexity",
            "predicted_rating",
            "predicted_users_rated",
        ]

        # Ensure all columns exist
        display_columns = [col for col in display_columns if col in filtered_df.columns]

        # Create a copy of the dataframe for display
        display_df = filtered_df.copy()

        # Add BoardGameGeek link column
        display_df["bgg_link"] = display_df.apply(
            lambda row: f"https://boardgamegeek.com/boardgame/{row['game_id']}", axis=1
        )

        # Update display columns to include the new link column
        display_columns.append("bgg_link")

        # Display interactive table
        st.dataframe(
            display_df[display_columns],
            use_container_width=True,
            hide_index=True,
            height=800,  # Increase default height to show more rows
            column_config={
                "bgg_link": st.column_config.LinkColumn(
                    "BoardGameGeek", display_text="BGG"
                )
            },
        )

    with tab2:
        st.header("Geek Rating Distribution")

        # Histogram of geek ratings for selected year
        fig = px.histogram(
            filtered_df,
            x="predicted_geek_rating",
            title=f"Distribution of Geek Ratings for {selected_year}",
            labels={"geek_rating": "Geek Rating"},
            marginal="box",  # Add box plot
        )
        st.plotly_chart(fig, use_container_width=True)

    with tab3:
        st.header("Analysis")

        # Select x-axis variable
        x_axis_options = [
            "predicted_complexity",
            "predicted_hurdle_prob",
            "predicted_users_rated",
            "predicted_rating",
        ]
        x_axis = st.selectbox("Select X-Axis Variable", x_axis_options, index=0)

        # Scatter plot with dynamic x-axis
        fig = px.scatter(
            filtered_df,
            x=x_axis,
            y="predicted_geek_rating",
            color="predicted_hurdle_prob",
            title=f"{x_axis.replace('_', ' ').title()} vs Geek Rating for {selected_year}",
            labels={
                x_axis: x_axis.replace("_", " ").title(),
                "predicted_geek_rating": "Geek Rating",
                "predicted_complexity": "Complexity",
                "predicted_rating": "Rating",
                "predicted_users_rated": "Users Rated",
                "predicted_hurdle_prob": "Likelihood of Rating",
            },
            hover_data=["name", "year_published"],
        )
        st.plotly_chart(fig, use_container_width=True)

    # Add data info in sidebar
    st.sidebar.header("Data Info")
    st.sidebar.text(f"Environment: {environment}")
    st.sidebar.text(
        f"Last Updated: {selected_job['latest_prediction'].strftime('%Y-%m-%d %H:%M:%S')}"
    )
    st.sidebar.text(f"Total Predictions: {selected_job['num_predictions']}")


if __name__ == "__main__":
    main()
