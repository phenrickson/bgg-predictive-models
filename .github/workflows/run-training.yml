name: Run Model Training

on:
  push:
    branches:
      - 'model/*'
  workflow_dispatch:
    inputs:
      output_dir:
        description: 'Output directory path (default: models/experiments)'
        required: false
        default: 'models/experiments'
        type: string
      model_args:
        description: 'Model arguments (space-separated list of model.key=value)'
        required: false
        type: string

jobs:
  run-training:
    runs-on: ubuntu-latest
    environment: ${{ github.ref == 'refs/heads/main' && 'PROD' || 'DEV' }}
    
    permissions:
      contents: read
      id-token: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.SERVICE_ACCOUNT_KEY }}

    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Configure Google Cloud Docker Auth
      run: gcloud auth configure-docker us-central1-docker.pkg.dev

    - name: Run training job
      run: |
        # Construct GCS output path
        GCS_OUTPUT_PATH="gs://${{ vars.GCS_BUCKET_NAME }}/${{ inputs.output_dir }}"
        
        # Create secrets in Secret Manager for both GCS and BigQuery access
        echo '${{ secrets.SERVICE_ACCOUNT_KEY }}' | gcloud secrets create bgg-training-sa-key-${{ github.run_id }} \
          --data-file=- \
          --replication-policy="automatic"

        # Create Cloud Run job
        gcloud run jobs create bgg-training-${{ github.run_id }} \
          --image us-central1-docker.pkg.dev/${{ vars.GCP_PROJECT_ID }}/bgg-predictive-models/training:latest \
          --region us-central1 \
          --memory 16Gi \
          --cpu 4 \
          --max-retries 0 \
          --task-timeout 3600 \
          --set-env-vars="GCP_PROJECT_ID=${{ vars.GCP_PROJECT_ID }},GCS_BUCKET_NAME=${{ vars.GCS_BUCKET_NAME }}" \
          --set-secrets="/app/credentials/service-account-key.json=bgg-training-sa-key-${{ github.run_id }}" \
          --command="uv" \
          --args="run,train.py,--output-dir,${GCS_OUTPUT_PATH},${{ inputs.model_args != '' && format('--model-args,{0}', inputs.model_args) || '' }}"

        # Execute the job and capture details
        echo "Starting Cloud Run job bgg-training-${{ github.run_id }}"
        EXECUTION_OUTPUT=$(gcloud run jobs execute bgg-training-${{ github.run_id }} \
          --region us-central1 2>&1)
        echo "$EXECUTION_OUTPUT"
        
        # Extract execution ID from output
        EXECUTION_ID=$(echo "$EXECUTION_OUTPUT" | grep -o 'bgg-training-[0-9a-z\-]*')
        
        if [ -n "$EXECUTION_ID" ]; then
          # Capture logs before potential failure
          echo "Fetching logs for execution $EXECUTION_ID"
          gcloud beta run jobs executions logs read $EXECUTION_ID \
            --region us-central1 \
            --project ${{ vars.GCP_PROJECT_ID }}
        fi
        
        # Log job URL for tracking
        echo "Job URL: https://console.cloud.google.com/run/jobs/executions/details/us-central1/$EXECUTION_ID/tasks?project=${{ vars.GCP_PROJECT_ID }}"
        echo "Monitor job progress at the URL above"
        
        # Clean up the secret
        gcloud secrets delete bgg-training-sa-key-${{ github.run_id }} --quiet

    # Commenting out cleanup to allow job inspection
    # - name: Cleanup
    #   if: always()
    #   run: |
    #     gcloud run jobs delete bgg-training-${{ github.run_id }} \
    #       --region us-central1 \
    #       --quiet
